import streamlit as st
import openai
import os

# Config da API
openai.api_key = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="Projeto Davar", layout="centered")

st.title("ğŸ¤– Davar â€“ escuta com presenÃ§a")
st.markdown("ğŸ”’ Nenhuma conversa Ã© salva. Ao fechar esta aba, tudo serÃ¡ apagado.")

# Inicializa histÃ³rico
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# BotÃ£o para limpar conversa
if st.button("ğŸ§¹ Nova conversa"):
    st.session_state.chat_history = []
    st.experimental_rerun()

# Entrada do usuÃ¡rio
user_input = st.text_input("Escreva aqui sua pergunta, desabafo ou reflexÃ£o:")

# FunÃ§Ã£o para gerar resposta com histÃ³rico
def gerar_resposta_com_gpt(historico):
    messages = [{"role": "system", "content": "VocÃª Ã© o Davar, um parceiro de escuta. Responda com empatia, profundidade e presenÃ§a."}]
    messages.extend(historico)
    resposta = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.7
    )
    return resposta.choices[0].message.content.strip()

# Processa entrada do usuÃ¡rio
if user_input:
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    resposta = gerar_resposta_com_gpt(st.session_state.chat_history)
    st.session_state.chat_history.append({"role": "assistant", "content": resposta})

# Exibe histÃ³rico formatado
for mensagem in st.session_state.chat_history:
    if mensagem["role"] == "user":
        st.markdown(f"**VocÃª:** {mensagem['content']}")
    elif mensagem["role"] == "assistant":
        st.markdown(f"**Davar:** {mensagem['content']}")
