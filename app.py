import streamlit as st
from openai import OpenAI
import os
import io

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

st.set_page_config(page_title="Projeto Davar", layout="centered")
st.title("ğŸ¤– Davar â€“ escuta com presenÃ§a")

# MANIFESTO
st.markdown("""
> **ğŸŒ± Bem-vindo ao Davar**  
> Aqui, vocÃª encontra uma escuta com presenÃ§a, sem julgamentos.  
> Um espaÃ§o para respirar, pensar, sentir e recomeÃ§ar.
>
> ğŸ”’ Nenhuma conversa Ã© salva. Ao fechar esta aba, tudo Ã© apagado.
""")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if st.button("ğŸ§¹ Nova conversa"):
    st.session_state.chat_history = []
    st.experimental_rerun()

audio_file = st.file_uploader("Ou envie sua fala como Ã¡udio (MP3, WAV, M4A):", type=["mp3", "wav", "m4a"])
user_input = ""

if audio_file:
    with st.spinner("Transcrevendo Ã¡udio..."):
        audio_bytes = audio_file.read()
        audio_buffer = io.BytesIO(audio_bytes)
        audio_buffer.name = audio_file.name

        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_buffer
        )
        user_input = transcript.text
        st.markdown(f"**VocÃª disse (transcrito):** {user_input}")
else:
    user_input = st.text_input("Escreva aqui sua pergunta, desabafo ou reflexÃ£o:")

# NOVO PROMPT DO DAVAR
def gerar_resposta_com_gpt(historico):
    system_prompt = (
        "VocÃª Ã© o Davar, uma presenÃ§a de escuta e cuidado. "
        "Responda com empatia, sem pressa, valorizando o que Ã© dito e acolhendo a pessoa como ela Ã©. "
        "Use uma linguagem prÃ³xima, com humanidade e sensibilidade. "
        "VocÃª pode fazer pequenas pausas poÃ©ticas ou reflexivas, se for apropriado. "
        "Evite parecer um robÃ´ ou um terapeuta tÃ©cnico. "
        "Seu papel Ã© escutar, refletir e estar junto com palavras que tocam e inspiram."
    )
    messages = [{"role": "system", "content": system_prompt}]
    messages.extend(historico)

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

if user_input:
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    resposta = gerar_resposta_com_gpt(st.session_state.chat_history)
    st.session_state.chat_history.append({"role": "assistant", "content": resposta})

for mensagem in st.session_state.chat_history:
    if mensagem["role"] == "user":
        st.markdown(f"**VocÃª:** {mensagem['content']}")
    elif mensagem["role"] == "assistant":
        st.markdown(f"**Davar:** {mensagem['content']}")
