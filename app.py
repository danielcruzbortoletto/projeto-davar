import streamlit as st
import openai
import os

# ConfiguraÃ§Ã£o da API
openai.api_key = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="Projeto Davar", layout="centered")

# Aviso de privacidade
st.markdown("ğŸ”’ As conversas nÃ£o sÃ£o salvas. Ao fechar esta aba, tudo serÃ¡ apagado.")

# Inicializa o histÃ³rico se ainda nÃ£o existir
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# TÃ­tulo do app
st.title("ğŸ¤– Davar â€“ escuta com presenÃ§a")

# Campo de entrada de texto
user_input = st.text_input("Digite sua pergunta ou reflexÃ£o:")

# FunÃ§Ã£o para gerar resposta com histÃ³rico
def gerar_resposta_com_gpt(historico):
    resposta = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "VocÃª Ã© o Davar, um parceiro de escuta. Responda com empatia, profundidade e respeito."},
            *historico
        ],
        temperature=0.7
    )
    return resposta.choices[0].message.content

# Se o usuÃ¡rio enviar uma pergunta
if user_input:
    # Adiciona pergunta ao histÃ³rico
    st.session_state.chat_history.append({"role": "user", "content": user_input})

    # Gera resposta com histÃ³rico
    resposta = gerar_resposta_com_gpt(st.session_state.chat_history)

    # Adiciona resposta ao histÃ³rico
    st.session_state.chat_history.append({"role": "assistant", "content": resposta})

# Exibe a conversa
for mensagem in st.session_state.chat_history:
    if mensagem["role"] == "user":
        st.markdown(f"**VocÃª:** {mensagem['content']}")
    elif mensagem["role"] == "assistant":
        st.markdown(f"**Davar:** {mensagem['content']}")
